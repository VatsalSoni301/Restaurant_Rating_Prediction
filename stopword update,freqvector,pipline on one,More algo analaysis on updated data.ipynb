{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./\"))\n",
    "# print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(\"../input/business/yelp_academic_dataset_business.csv\")\n",
    "df1 = pd.read_csv(\"../input/review/yelp_academic_dataset_review.csv\")\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_final = pd.merge(df0, df1, how='inner', on=['business_id', 'business_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_final['stars_x'] = df_final['stars_x'].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# # df = df_final.sample(df['stars'],n=80000)\n",
    "# df = df_final[df_final['stars_x']==1]\n",
    "# df_2 = df_final[df_final['stars_x']==2]\n",
    "# df_3 = df_final[df_final['stars_x']==3]\n",
    "# df_4 = df_final[df_final['stars_x']==4]\n",
    "# df_5 = df_final[df_final['stars_x']==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# print(df.shape)\n",
    "# print(df_2.shape)\n",
    "# print(df_3.shape)\n",
    "# print(df_4.shape)\n",
    "# print(df_5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# df = df.sample(n=10000)\n",
    "# df_2 = df_2.sample(n=10000)\n",
    "# df_3 = df_3.sample(n=10000)\n",
    "# df_4 = df_4.sample(n=10000)\n",
    "# df_5 = df_5.sample(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# print(df.shape)\n",
    "# print(df_2.shape)\n",
    "# print(df_3.shape)\n",
    "# print(df_4.shape)\n",
    "# print(df_5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# # df.append(df_2, ignore_index = True) \n",
    "# df = pd.concat([df,df_2,df_3,df_4,df_5])\n",
    "# print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_final.sample(n=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# df.append(df_3, ignore_index = True) \n",
    "# df.append(df_4, ignore_index = True) \n",
    "# df.append(df_5, ignore_index = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# result.columns\n",
    "df = df[['name','business_id','review_count','user_id','text','is_open','hours','stars_x','useful']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.columns\n",
    "# result.shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# df.to_csv(\"merge.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"merge.csv\")\n",
    "# df = df.samples(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "# df = df.sample(n=1000)\n",
    "# df['is_open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['name','business_id','user_id','hours'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'stars_x':'stars'}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df.drop(['Unnamed: 10','Unnamed: 11','review_id','date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df.drop(['user_id','business_id','type'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df.reset_index()\n",
    "df = df.drop(['index'],axis=1)\n",
    "nan = df[df['stars'].isnull()]\n",
    "nan1 = df[df['text'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from textblob import TextBlob\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from sklearn.utils import resample\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"yelp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df.drop(['Unnamed: 10','Unnamed: 11','review_id','date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df.drop(['user_id','business_id','type'],axis=1)\n",
    "# df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UPSAMPLE\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Coversion in lower case ###\n",
    "\n",
    "df['text'] = df['text'].str.lower()\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removal of stop words\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "stop=stop[0:144]\n",
    "stop.append('back')\n",
    "stop.append('n\\'t')\n",
    "stop.append('dice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exclude stopwords with Python's list comprehension and pandas.DataFrame.apply.\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### INCLUSION OF LENGTH OF REVIEW\n",
    "\n",
    "df['length'] = df['text'].apply(len)\n",
    "df['stars'] = df['stars'].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Review vs Stars\n",
    "\n",
    "graph = sns.FacetGrid(data=df,col='stars')\n",
    "graph.map(plt.hist,'length',bins=50,color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Removal of meaningless thing from text\n",
    "\n",
    "def fun(x):\n",
    "#     print(x)\n",
    "    blob=TextBlob(x)\n",
    "#     print(\"blob \",blob)\n",
    "    verb=[]\n",
    "    s=\" \"\n",
    "    for word, tag in blob.tags:\n",
    "#         print(\"ffff\")\n",
    "        if tag == 'RB' or tag=='RBR' or tag=='RBS' or tag=='JJ' or tag=='JJR':\n",
    "            verb.append(word)\n",
    "    s=s.join(verb)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_word_cloud(data):\n",
    "    '''\n",
    "    Function to plot word cloud from a pandas series\n",
    "    Input: data: pandas.core.series.Series object\n",
    "    Output: Wordcloud of most recurrent words in data\n",
    "        for plots to be in ipython notebook include following line before calling this function\n",
    "        %matplotlib inline \n",
    "    '''\n",
    "    # take relative word frequencies into account, lower max_font_size\n",
    "    wordcloud = WordCloud(max_font_size=40, relative_scaling=.5).generate(str(data))\n",
    "    plt.figure()\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(fun)\n",
    "\n",
    "# strv=df.groupby('stars').mean()\n",
    "# stval.corr()\n",
    "# strv.mean('cool')\n",
    "# strv\n",
    "\n",
    "# strv.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STEMMING\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x:' '.join([stemmer.stem(word) for word in x.split() if word in stemmer.stem(word)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['text']\n",
    "stars = df['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_cloud(df[\"text\"].loc[df.stars == 1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_cloud(df[\"text\"].loc[df.stars == 2,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_cloud(df[\"text\"].loc[df.stars == 3,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_cloud(df[\"text\"].loc[df.stars == 4,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_cloud(df[\"text\"].loc[df.stars == 5,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_review_tokens = df.text.sum()\n",
    "yelp_review_vocabulary = nltk.FreqDist(yelp_review_tokens.split())\n",
    "yelp_review_vocabulary_counts = np.array(list(yelp_review_vocabulary.values()))\n",
    "yelp_review_vocabulary_tokens = list(yelp_review_vocabulary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Zipf plot\n",
    "ranks = np.arange(1, len(yelp_review_vocabulary_counts)+1)\n",
    "indices = np.argsort(-yelp_review_vocabulary_counts)\n",
    "frequencies = yelp_review_vocabulary_counts[indices]\n",
    "fig3 = plt.figure(figsize=(12, 8))\n",
    "plt.loglog(ranks, frequencies, marker=\".\")\n",
    "plt.title(\"Zipf plot for Yelp corpus tokens\")\n",
    "plt.xlabel(\"Frequency rank of token\")\n",
    "plt.ylabel(\"Absolute frequency of token\")\n",
    "plt.grid(True)\n",
    "for n in list(np.logspace(-0.5, np.log10(len(yelp_review_vocabulary_counts)), 20).astype(int)):\n",
    "    dummy = plt.text(ranks[n-1], frequencies[n-1], \" \" + yelp_review_vocabulary_tokens[indices[n-1]], \n",
    "                 verticalalignment=\"bottom\",\n",
    "                 horizontalalignment=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1={}\n",
    "dict1[1]=[]\n",
    "dict1[2]=[]\n",
    "dict1[3]=[]\n",
    "dict1[4]=[]\n",
    "dict1[5]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive=0\n",
    "negative=0\n",
    "count=0\n",
    "#polarity and star graph \n",
    "\n",
    "for i in df['text']:\n",
    "    blob = TextBlob(i)\n",
    "    feel = blob.sentiment\n",
    "    if feel.polarity > 0:\n",
    "        positive = positive + 1\n",
    "    else:\n",
    "        negative = negative + 1\n",
    "    if(feel.polarity<0.10):\n",
    "        df.loc[count, 'sentiment'] = int(1)\n",
    "    elif(feel.polarity>=0.10 and feel.polarity < 0.16):\n",
    "        df.loc[count, 'sentiment'] = int(2)\n",
    "    elif(feel.polarity>=0.16 and feel.polarity < 0.025):\n",
    "        df.loc[count, 'sentiment'] = int(3)\n",
    "    elif(feel.polarity>=0.025 and feel.polarity < 0.35):\n",
    "        df.loc[count, 'sentiment'] = int(4)\n",
    "    else:\n",
    "        df.loc[count, 'sentiment'] = int(5)\n",
    "    w=df.loc[count, 'stars']\n",
    "#     print(w)\n",
    "    dict1[int(w)].append(feel.polarity)\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = [1,2,3,4,5]\n",
    "y = list(dict1.values())\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"X-axis\")\n",
    "plt.ylabel(\"Y-axis\")\n",
    "plt.title(\"Polarity Graph\")\n",
    "for i in range(len(y)):\n",
    "    plt.plot(x,[pt[i] for pt in y],label = 'id %s'%(i+1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REASON FOR BALANCING CAN BE SEEN BY GRAPH SHOWING VARIATION IN COLLECTION OF RATING COUNT ###$\n",
    "\n",
    "N_star_categories = 5\n",
    "colors = np.array(['#660000', '#ff4d4d', '#ffb3b3', '#99e699', '#29a329'])\n",
    "stars_labels = np.array(range(N_star_categories)) + 1;\n",
    "#star_category_dist_fig = plt.figure(figsize=(12,8))\n",
    "bar_plot_indices = np.arange(N_star_categories) \n",
    "star_category_absolute_frequencies = df.stars.value_counts(ascending=True);\n",
    "star_category_relative_frequencies = np.array(star_category_absolute_frequencies)/float(sum(star_category_absolute_frequencies))\n",
    "sns.set()\n",
    "sns.set(style=\"white\")\n",
    "fig2 = plt.figure(figsize=(12, 8))\n",
    "ax = sns.barplot(x=bar_plot_indices + 1, y=star_category_relative_frequencies)\n",
    "ax.set_xlabel('Star Category');\n",
    "ax.set_ylabel('Relative Frequency');\n",
    "ax.set_title('Star Category Distribution for {0} Reviews'.format(len(df)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars_1 = df[df['stars']==1]\n",
    "stars_2 = df[df['stars']==2]\n",
    "stars_3 = df[df['stars']==3]\n",
    "stars_5 = df[df['stars']==5]\n",
    "stars_4 = df[df['stars']==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=star_category_absolute_frequencies[4]\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority_upsampled_1 = resample(stars_1, \n",
    "                                 replace=True, \n",
    "                                 n_samples=z,\n",
    "                                 random_state=123)\n",
    "df_minority_upsampled_2 = resample(stars_2, \n",
    "                                 replace=True, \n",
    "                                 n_samples=z,\n",
    "                                 random_state=123)\n",
    "df_minority_upsampled_3 = resample(stars_3, \n",
    "                                 replace=True, \n",
    "                                 n_samples=z,\n",
    "                                 random_state=123)\n",
    "df_minority_upsampled_5 = resample(stars_5, \n",
    "                                 replace=True, \n",
    "                                 n_samples=z,\n",
    "                                 random_state=123)\n",
    "# df_upsampled = df\n",
    "df_upsampled = pd.concat([stars_4, df_minority_upsampled_1,df_minority_upsampled_2,df_minority_upsampled_3,df_minority_upsampled_5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we’ll get less biased predictions if we train the system on balanced data. This means that ideally we should have the same number of examples of each review type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_star_categories = 5\n",
    "colors = np.array(['#660000', '#ff4d4d', '#ffb3b3', '#99e699', '#29a329'])\n",
    "stars_labels = np.array(range(N_star_categories)) + 1;\n",
    "#star_category_dist_fig = plt.figure(figsize=(12,8))\n",
    "bar_plot_indices = np.arange(N_star_categories) \n",
    "star_category_absolute_frequencies = df_upsampled.stars.value_counts(ascending=True);\n",
    "star_category_relative_frequencies = np.array(star_category_absolute_frequencies)/float(sum(star_category_absolute_frequencies))\n",
    "sns.set()\n",
    "sns.set(style=\"white\")\n",
    "fig2 = plt.figure(figsize=(12, 8))\n",
    "ax = sns.barplot(x=bar_plot_indices + 1, y=star_category_relative_frequencies)\n",
    "ax.set_xlabel('Star Category');\n",
    "ax.set_ylabel('Relative Frequency');\n",
    "ax.set_title('Star Category Distribution for {0} Reviews'.format(len(df_upsampled)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = df_upsampled['stars']\n",
    "print(Counter(stars))\n",
    "balanced_y = stars\n",
    "balanced_y = df_upsampled['stars'].round(0).astype(int)\n",
    "balanced_x = df_upsampled['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_upsampled\n",
    "# df_upsampled.reset_index()\n",
    "\n",
    "### Data bais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df_upsampled[['sentiment','text','stars','review_count','is_open','useful']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.groupby('stars', as_index=False)['sentiment'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TF-IDF ###\n",
    "### This vectorizer breaks text into single words and bi-grams and then calculates the TF-IDF representation\n",
    "\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "# vectors = vectorizer.fit_transform(balanced_x)\n",
    "balanced_x.shape\n",
    "df2=df2.drop(['stars'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2\n",
    "\n",
    "# print(vectors)\n",
    "# print(vectors.shape[0])\n",
    "# print(vectors.shape[1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df2, balanced_y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_text_data = FunctionTransformer(lambda x: x['text'], validate=False)\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[['sentiment']], validate=False)\n",
    "get_count = FunctionTransformer(lambda x: x[['review_count']], validate=False)\n",
    "get_bool = FunctionTransformer(lambda x: x[['is_open']], validate=False)\n",
    "get_useful = FunctionTransformer(lambda x: x[['useful']], validate=False)\n",
    "just_text_data = get_text_data.fit_transform(X_train)\n",
    "just_numeric_data = get_numeric_data.fit_transform(X_train)\n",
    "just_count = get_count.fit_transform(X_train)\n",
    "just_open = get_bool.fit_transform(X_train)\n",
    "just_useful = get_useful.fit_transform(X_train)\n",
    "print('Text Data')\n",
    "print(just_text_data.head())\n",
    "print('\\nNumeric Data')\n",
    "print(just_numeric_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Predict Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "process_and_join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "#                     ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "                ,\n",
    "                ('text_features1', Pipeline([\n",
    "                    ('selector', get_count)\n",
    "#                     ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "                ,\n",
    "                ('text_features2', Pipeline([\n",
    "                    ('selector', get_bool)\n",
    "#                     ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )\n",
    "\n",
    "pl = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "pl1 = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf',MLPClassifier(hidden_layer_sizes=(5,5), max_iter=50, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=21,tol=0.000000001))\n",
    "    ])\n",
    "pl2 = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', MultinomialNB())\n",
    "    ])\n",
    "# pl3 = Pipeline([\n",
    "#         ('union', process_and_join_features),\n",
    "#         ('clf', GradientBoostingClassifier(learning_rate=0.1,max_depth=5,max_features=0.5,random_state=999999))\n",
    "#     ])\n",
    "pl3 = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf',LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                         multi_class='multinomial'))\n",
    "    ])\n",
    "\n",
    "# pl4 = Pipeline([\n",
    "#         ('union', process_and_join_features),\n",
    "#         ('clf',LogisticRegression(random_state=0, solver='lbfgs',\n",
    "#                          multi_class='multinomial'))\n",
    "#     ])\n",
    "pl5 = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf',svm.SVC(gamma='scale', decision_function_shape='ovo'))\n",
    "    ])\n",
    "pl6 = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf',KNeighborsClassifier(n_neighbors=3))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test1 = pl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test1)\n",
    "print(len(y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test\n",
    "print(accuracy_score(y_test,y_test1))\n",
    "ovr=accuracy_score(y_test,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl1.fit(X_train, y_train)\n",
    "y_test2 = pl1.predict(X_test)\n",
    "print(accuracy_score(y_test,y_test2))\n",
    "mlp=accuracy_score(y_test,y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl2.fit(X_train, y_train)\n",
    "y_test3 = pl2.predict(X_test)\n",
    "print(accuracy_score(y_test,y_test3))\n",
    "naive=accuracy_score(y_test,y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl3.fit(X_train, y_train)\n",
    "y_test4 = pl3.predict(X_test)\n",
    "print(accuracy_score(y_test,y_test4))\n",
    "logistic=accuracy_score(y_test,y_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl4.fit(X_train, y_train)\n",
    "# y_test5= pl4.predict(X_test)\n",
    "# print(accuracy_score(y_test,y_test5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl6.fit(X_train, y_train)\n",
    "y_test7= pl6.predict(X_test)\n",
    "print(accuracy_score(y_test,y_test7))\n",
    "KNN=accuracy_score(y_test,y_test7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl5.fit(X_train, y_train)\n",
    "y_test6= pl5.predict(X_test)\n",
    "print(accuracy_score(y_test,y_test6))\n",
    "SVM=accuracy_score(y_test,y_test6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "sizes=[]\n",
    "# print(kmean)\n",
    "sizes.append(ovr)\n",
    "# colors = ['gold', 'blue', 'yellow','red','green']\n",
    "sizes.append(mlp)\n",
    "labels =  'onevsAll', 'NN','naive','logistic','SVM','KNN',\n",
    "sizes.append(naive)\n",
    "sizes.append(logistic)\n",
    "sizes.append(SVM)\n",
    "sizes.append(KNN)\n",
    "# explode = (0, 0,0,0,0)\n",
    "# plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "# autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "# plt.axis('equal')\n",
    "# plt.show()\n",
    "x = np.arange(6)\n",
    "plt.bar(x, height=sizes) \n",
    "plt.xticks(x, labels)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
